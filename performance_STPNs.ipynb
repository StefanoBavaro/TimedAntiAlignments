{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1716642504601,"user":{"displayName":"Stefano Bavaro","userId":"17036106314327297066"},"user_tz":-120},"id":"GS7gt-OF0CDX"},"outputs":[],"source":["#performance test of the code\n","\n","import time\n","import numpy as np\n","import random\n","from itertools import product\n","import decimal\n","\n","import random\n","from decimal import Decimal, ROUND_HALF_UP\n","\n","def round_to_two_decimal_places(value):\n","    #Rounds a value to two decimal places with ROUND_HALF_UP.\n","    return Decimal(value).quantize(Decimal(\"0.01\"), rounding=ROUND_HALF_UP)\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1716642504602,"user":{"displayName":"Stefano Bavaro","userId":"17036106314327297066"},"user_tz":-120},"id":"N7EhAvdP0CDY"},"outputs":[],"source":["def generate_lower_bound_log(model, current_index, current_point, result, step_L , brought = 0):\n","    if current_index == len(model)-1:\n","        curr_point = current_point.copy()\n","        point = (curr_point + [curr_point[current_index-1] + model[current_index][0]])\n","        #print(point)\n","        result.append(point)\n","        return\n","\n","    lower_bound, upper_bound = model[current_index]\n","    for i in np.arange(lower_bound + brought, upper_bound + brought + step_L, step_L):\n","        current_point.append(i)\n","        generate_lower_bound_log(model, current_index + 1, current_point, result , step_L, i )\n","        current_point.pop()\n","\n","def generate_upper_bound_log(model, current_index, current_point, result, step_L, brought = 0):\n","    if current_index == len(model)-1:\n","        curr_point = current_point.copy()\n","        point = (curr_point + [curr_point[current_index-1] + model[current_index][1]])\n","        #print(point)\n","        result.append(point)\n","        return\n","\n","    lower_bound, upper_bound = model[current_index]\n","    for i in np.arange(lower_bound + brought, upper_bound + brought+ step_L, step_L):\n","        current_point.append(i)\n","        generate_upper_bound_log(model, current_index + 1, current_point, result , step_L, i )\n","        current_point.pop()\n","\n","def max_point(model):\n","    #returns the maximal point \\sigma_M of the model \n","    max_point = []\n","    for i in range(len(model)):\n","        if i == 0:\n","            max_point.append(model[i][1])\n","        else:\n","            max_point.append(model[i][1] + max_point[i-1])\n","    return max_point\n","\n","def min_point(model):\n","    #returns the minimal point \\sigma_m of the model \n","    min_point = []\n","    for i in range(len(model)):\n","        if i == 0:\n","            min_point.append(model[i][0])\n","        else:\n","            min_point.append(model[i][0] + min_point[i-1])\n","    return min_point\n","\n","def generate_random_example(dimension, cardinality, random_model):\n","    #generates a random example of problem given the parameters of dimension and cardinality, \n","    #i.e. a sequential model with #trns = dimension and a random log accepted by the model with #traces = cardinality\n","    # if random_model = False, then the model will have all intervals as [0,1]\n","    if random_model == True:\n","        model = generate_random_model(dimension)\n","    else:\n","        model = [ [0,1] for i in range(dimension)]\n","\n","    log = generate_random_log(model, cardinality)\n","    return log, model\n","\n","def generate_random_model(dimension):\n","    #generates a random sequential model with the given dimension, with the extrema of the intervals as explained in the paper\n","    model = []\n","    for i in range(dimension):\n","        # Generate random bounds\n","        lower_bound = round(random.uniform(0, 5),2)\n","        upper_bound = lower_bound + round(random.uniform(0, 5),2)\n","        model.append((lower_bound, upper_bound))  \n","    print(model)\n","\n","    return model\n","\n","def generate_random_log(model, cardinality):\n","    #Generates a log with n = cardinality random (a random value taken from every interval) traces accepted by the model\n","    log = []\n","\n","    for j in range(cardinality):\n","        ex = []\n","        for i in range(len(model)):\n","            if i == 0:\n","                # Generate a random value within the model bounds and round it to two decimal places\n","                ex.append(round(random.uniform(model[i][0], model[i][1]),2))\n","            else:\n","                # Add the previous value to the new random value, then round to two decimal places\n","                ex.append(round(random.uniform(model[i][0], model[i][1]) + ex[i-1],2))\n","        log.append(ex)\n","\n","    return log\n","\n","def bf_search_space(counter, dimension, brought, model, gamma, search_space,step, distance_type):\n","    #build the search space (set of \"all\" points accepted by the model) brute force\n","    #as the space is continuous, the parameter \"step\" determines the number of splits of the space of each dimension into equidistant points\n","    if counter-1 == dimension:\n","        # Base case: all loops have been executed\n","        search_space.append(gamma.copy())\n","        #print(gamma, search_space)\n","        return search_space\n","    else:\n","        lower = model[counter-1][0] + brought\n","        upper = model[counter-1][1] + brought\n","        for i in  np.linspace(lower, upper, step):\n","            gamma.append(i)  # Modify the values for the current loop\n","            if distance_type == 0:\n","                bf_search_space(counter + 1, dimension, i, model , gamma, search_space, step, distance_type)  #Recursively call the function for the next loop\n","            else:\n","                bf_search_space(counter + 1, dimension, 0, model , gamma, search_space, step, distance_type)\n","            gamma.pop()  # Remove the current loop's value\n","\n","    if counter == 1:\n","        print('done')\n","        return search_space\n","\n","def search_space_delay(model, step):\n","    #builds the search space when using the delay only distance\n","    #(discretized, still with the parameter step determining the number of splits of the space of each dimension into equidistant points)\n","\n","    # Create a list of linspaces for each interval\n","    linspaces = [np.linspace(interval[0], interval[1], step) for interval in model]\n","\n","    # Generate all combinations of points using itertools.product\n","    combinations = set(product(*linspaces))\n","\n","    return combinations\n","\n","\n","def find_aa(model, L, step, distance_type):\n","    #finds all possible anti-alignments considering the discretized search space, and comparing every point brute force\n","\n","    dimension = len(model)\n","    #print('dimension:', dimension)\n","\n","    if distance_type == 0:\n","        search_space = bf_search_space(1, dimension, 0, model, [], [], step, distance_type)\n","    else:\n","        search_space = search_space_delay(model, step)\n","\n","    print(model)\n","    print('Search space:', search_space)\n","\n","\n","    # Initialize variables\n","    max_distance = float('-inf')\n","    max_points = []\n","\n","    # Convert the list L to a numpy array for efficient vector operations\n","    L_array = np.array(L)\n","\n","    # Iterate over each point in the search space\n","    for gamma in search_space:\n","        # Convert gamma to a numpy array for efficient vector operations\n","        gamma_array = np.array(gamma)\n","\n","        # Calculate the minimum distance for the current gamma\n","        distances = np.linalg.norm(L_array - gamma_array, ord=1, axis=1)  # Efficient L1 norm computation\n","        min_distance = np.min(distances)  # Minimum distance to any point in L\n","\n","        # Update max_distance and max_points based on the minimum distance\n","        if min_distance > max_distance:\n","            max_distance = min_distance\n","            max_points = [gamma]\n","        elif min_distance == max_distance:\n","            max_points.append(gamma)\n","\n","    return max_distance, max_points\n","\n","def trace_back_sigmas_for_gammas(anti_alignments , L, model, max_distance):\n","    for gamma in anti_alignments:\n","        #print('Gamma:', gamma)\n","        for sigma in L:\n","            distance = sum([abs(gamma[i] - sigma[i]) for i in range(len(model))])\n","            if distance == max_distance:\n","                print('Sigma:', sigma, 'Gamma:' , gamma, 'Distance:', distance)\n","                #print('Distance:', sum([abs(gamma[i] - sigma[i]) for i in range(len(model))]))\n","\n","def transform_log(L, model):\n","    #Transforms the log into the equivalent using flow functions (for delay only distance)\n","    for i, trace in enumerate(L):\n","        if len(model) == 1:\n","            trace_list = list([trace])\n","        else:\n","            trace_list = list(trace)\n","\n","        old_trace = trace_list.copy()\n","\n","        # Calculate deltas and ensure they are rounded to two decimal places\n","        for j in range(1, len(trace_list)):\n","            # Calculate the difference and round to two decimal places\n","            trace_list[j] = round(trace_list[j] - old_trace[j - 1],2)\n","\n","        L[i] = trace_list\n","\n","    return L"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1716642513969,"user":{"displayName":"Stefano Bavaro","userId":"17036106314327297066"},"user_tz":-120},"id":"TAQo-2h10CDb"},"outputs":[],"source":["import pulp as plp\n","import time\n","\n","def LPSolver(model, log, distance_type):\n","#Linear Programming solver with constraints and variables as described in the paper\n","\n","    # Define the dimensionality of the problem\n","    n = len(model) #dimension of the space\n","    m = len(log) #number of points in L\n","\n","    if distance_type == 1: #if delay-only distance is used, the log is transformed in equivalent flow functions traces\n","        start =  time.time()\n","        log = transform_log(log, model)\n","        elapsed_time = time.time() - start\n","        print(elapsed_time)\n","\n","    # Create the LP problem\n","    prob = plp.LpProblem(\"Maximize minimal manhattan distance\", plp.LpMaximize)\n","\n","    # Define the decision variables\n","    x = plp.LpVariable.dicts(\"x\", range(n), lowBound=0, cat = 'Continuous')\n","\n","    #Define the variable to maximize\n","    z = plp.LpVariable(\"z\", lowBound=0, cat = 'Continuous')\n","\n","    # Define the constraints for x, i.e. the search space constraints\n","    if distance_type == 0:\n","        for i in range(n):\n","            if i == 0:\n","                prob += x[i] >= model[i][0]\n","                prob += x[i] <= model[i][1]\n","            else:\n","                prob += x[i] >= model[i][0] + x[i-1]\n","                prob += x[i] <= model[i][1] + x[i-1]\n","    else:\n","        for i in range(n):\n","            prob += x[i] >= model[i][0]\n","            prob += x[i] <= model[i][1]\n","\n","\n","    # Define the constraints for the absolute value of the difference between x and each point in L\n","    diff_plus = plp.LpVariable.dicts(\"diff_plus\", (range(m), range(n)), lowBound=0, cat = 'Continuous')\n","    diff_minus = plp.LpVariable.dicts(\"diff_minus\", (range(m), range(n)), lowBound=0, cat = 'Continuous')\n","\n","    M = np.linalg.norm(np.array(max_point(model)) - np.array(min_point(model)), ord=1)\n","    print(\"M:\",M)\n","\n","    #binary variables\n","    b = plp.LpVariable.dicts(\"b\", (range(m), range(n)), cat = 'Binary')\n","\n","    for j in range(m): #for every sigma in L\n","        for i in range(n): #for every dimension\n","            #print(i)\n","            if len(model) == 1: #if the model is 1-dimensional\n","                prob += diff_plus[j][i] - diff_minus[j][i] == log[j] - x[i]\n","            else:\n","                prob += diff_plus[j][i] - diff_minus[j][i] == log[j][i] - x[i]\n","\n","            prob += diff_plus[j][i] <= M*b[j][i]\n","            prob += diff_minus[j][i] <= M*(1-b[j][i])\n","\n","        prob += z <= plp.lpSum([diff_plus[j][i] + diff_minus[j][i] for i in range(n)])\n","\n","    #print(prob)\n","\n","    # Define the objective function\n","    prob += z\n","\n","    # Solve the problem\n","    prob.solve()\n","\n","    # Print the results\n","    print(\"Status:\", plp.LpStatus[prob.status])\n","    #print(\"Max Distance:\", plp.value(prob.objective))\n","\n","    optimal_point = [plp.value(x[i]) for i in range(n)]\n","    #print('Optimal Point:', optimal_point)\n","\n","    return plp.value(prob.objective), optimal_point, prob.numVariables(), prob.numConstraints()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzF9IMtT0CDc"},"outputs":[],"source":["def brute_force_solver(model, log, step, distance_type):\n","    #the log is to be transformed or not depending on whether the LP solver has already been used for the same log\n","    #in such case, the log is already transformed\n","    #if the BF solver is the only one used, this line has to be uncommented \n","    \"\"\" \n","    if distance_type == 1:\n","        log = transform_log(log, model)\n","    \"\"\"\n","    max_distance, max_points = find_aa(model, log, step, distance_type)\n","    #print('Max Distance:', max_distance)\n","    #print('Optimal Point:', max_points[0])\n","\n","    return max_distance, max_points\n","\n","import json\n","import ast\n","\n","def retrieve_example(cardinality, dimension):\n","  #retrieves the log and model from the JSON file given the cardinality and dimension of the problem\n","  #it retrieves it only for distance type 0 (stamp only), to retrieve the \"original\" log\n","\n","  filepath = \"/content/drive/MyDrive/lp_solver_logs.json\"\n","\n","  # Load JSON data from a file\n","  with open(filepath, \"r\") as f:\n","      json_data = json.load(f)\n","\n","  key_pattern = f\"{cardinality}-{dimension}-0\"\n","\n","  # Find the entry with the corresponding key\n","  for key, entry in json_data.items():\n","      if entry.get(\"Key\") == key_pattern:\n","          # Get the Model and Log from the \"Log Data\"\n","          model = ast.literal_eval(entry.get(\"Log Data\", {}).get(\"Model\"))\n","          log = entry.get(\"Log Data\", {}).get(\"Log\")\n","          return model, log\n","\n","  # If the key pattern is not found, return a message\n","  return {\"error\": \"No data found for the given key pattern\"}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":874,"status":"error","timestamp":1715270447159,"user":{"displayName":"Stefano Bavaro","userId":"17036106314327297066"},"user_tz":-120},"id":"MGpfejcM0CDc","outputId":"5e126e2a-d8d7-462a-a006-53caed3c5ec7"},"outputs":[{"ename":"NameError","evalue":"name 'generate_random_example' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-1588d25dbbbe>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# Create a unique key for each (cardinality, dimension, distance_type)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_random_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m#print(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'generate_random_example' is not defined"]}],"source":["import time\n","import json\n","import pandas as pd\n","from itertools import product\n","import os\n","\n","# Parameters to generate examples\n","cardinalities = [10,100]\n","dimensions = [10]\n","distance_types = [0,1]\n","#step = 10\n","\n","# Generate list of pairs of cardinalities and dimensions\n","pairs = product(cardinalities, dimensions)\n","\n","# File paths for storing results\n","json_filename = \"/content/drive/MyDrive/BF_solver_logs.json\"\n","csv_filename = \"/content/drive/MyDrive/BF_solver_results.csv\"\n","json_filename2 = \"/content/drive/MyDrive/BF_solver_logs2.json\"\n","\n","def save_log_to_json(key, log_data, file_path):\n","    #Saves log and model to a JSON file with a unique identifier, along with the key\n","    \n","    # Convert the data to a serializable format\n","    log_data_serializable = {str(k): v for k, v in log_data.items()}\n","\n","    # Generate a unique identifier for the log\n","    log_id = hash(json.dumps(log_data_serializable, sort_keys=True))\n","\n","    # Structure for storing the log with the key\n","    log_entry = {\n","        \"Key\": key,\n","        \"Log Data\": log_data_serializable\n","    }\n","\n","    # Create or update the JSON file\n","    if not os.path.exists(file_path):\n","        with open(file_path, 'w') as f:\n","            json.dump({}, f, indent=4)\n","\n","    # Load existing data\n","    with open(file_path, 'r') as f:\n","        existing_data = json.load(f)\n","\n","    # Add the new log with the unique identifier\n","    existing_data[str(log_id)] = log_entry\n","\n","    # Write back the updated data\n","    with open(file_path, 'w') as f:\n","        json.dump(existing_data, f, indent=4)\n","\n","    return log_id  # Return the unique identifier to reference this log\n","\n","# Function to append to a CSV file\n","def append_results_to_csv(results_dict, file_path):\n","    #Appends data (result) to a CSV file. \n","\n","    df = pd.DataFrame([results_dict])\n","    file_exists = os.path.exists(file_path)\n","\n","    # If the file does not exist or is empty, write headers\n","    if not file_exists or os.path.getsize(file_path) == 0:\n","        df.to_csv(file_path, mode='w', index=False, header=True, sep=';')\n","    else:\n","        df.to_csv(file_path, mode='a', index=False, header=False, sep=';')  # Append without headers\n","\n","\n","# Dictionary to store results\n","lp_results = {}\n","\n","# LP-based experiments loop\n","for cardinality, dimension in pairs:\n","\n","    # Generate\\retrieve example \n","    #model, log, = retrieve_example(cardinality, dimension)\n","    log, model = generate_random_example(dimension, cardinality, random_model = True)\n","\n","    #print(model)\n","\n","    for distance_type in distance_types:\n","        key = f\"{cardinality}-{dimension}-{distance_type}\"\n","        print(f\"Cardinality: {cardinality}, Dimension: {dimension}, Distance Type: {distance_type}\")\n","\n","        # Save the log data to the JSON file and get the unique ID\n","        #The log is initially saved to the \"backup\" json file in order to have it saved even if the execution is interrupted\n","        log_id = save_log_to_json(key, {\"Model\": str(model), \"Log\": log}, json_filename2) \n","\n","        start_time = time.time()\n","        max_dist_LP, opt_point_LP, numVars, numConstr = LPSolver(model, log, distance_type)\n","        elapsed_time_LP = time.time() - start_time\n","\n","        start_time_BF = time.time()\n","        max_dist_BF, opt_point_BF = brute_force_solver(model, log, 5, distance_type)\n","        elapsed_time_BF = time.time() - start_time_BF\n","\n","        # Save the log and model in json file\n","        log_id = save_log_to_json(key, {\"Model\": str(model), \"Log\": log}, json_filename)\n","\n","        # Store the results\n","        result_data = {\n","            'Key': key,\n","            'Dimension': dimension,\n","            'Cardinality': cardinality,\n","            'Distance Type': distance_type,\n","            #'Model': str(model),  # Ensure this is serializable\n","            #'Log': str(L),  # Ensure this is serializable\n","            'Elapsed Time (LP)': elapsed_time_LP,\n","            'Elapsed Time (BF)': elapsed_time_BF,\n","            #'Number of Variables (LP)': numVars,\n","            #'Number of Constraints (LP)': numConstr,\n","            'Solution (LP)': str(opt_point_LP),  # Ensure this is serializable\n","            'Solution (BF)': str(opt_point_BF),  # Ensure this is serializable\n","            'Max Distance (LP)': max_dist_LP,\n","            'Max Distance (BF)': max_dist_BF,\n","        }\n","\n","        append_results_to_csv(result_data, csv_filename)\n","\n","\n","        # Display the results\n","        print(f\"Elapsed Time (LP): {elapsed_time_LP:.6f} seconds\")\n","        print(f\"Elapsed Time (BF): {elapsed_time_BF:.6f} seconds\")\n","        #print(f\"Number of Variables (LP): {numVars}\")\n","        #print(f\"Number of Constraints (LP): {numConstr}\")\n","        print(f\"Max Distance (LP): {max_dist_LP}\")\n","        print(f\"Max Distance (BF): {max_dist_BF}\")\n","\n","        print()\n","\n","        # Save the results to both JSON and CSV files\n","        #append_results_to_json(lp_results, json_filename)\n","\n","print(f\"LP-based results successfully appended {csv_filename}.\")\n"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
